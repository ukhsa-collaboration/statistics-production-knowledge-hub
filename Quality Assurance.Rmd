---
title: "Quality Assurance"
author: "Olivia Swarthout"
date: "7 November, 2022"    #"`r format(Sys.time(), '%d %B, %Y')`"
draft: true
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: false
    template: "- assets/Templates/html_template.html"
  word_document:
    reference_docx: "- assets/Templates/UKHSA plain document template.dotx"
knit: (function(inputFile, encoding){rmarkdown::render(inputFile, envir = globalenv(), encoding = encoding, output_dir = "./", output_format = "all")})

versioncontrol: "`r ukhsaGuidanceDocs::VersionHistory(  c('24/10/2022', 'First draft')  )`"
---


```{r setup, echo=F, include=F}
library(tidyverse)
library(readxl)
library(ukhsaGuidanceDocs)
knitr::opts_chunk$set(echo = F)
SetUpReferenceList("- assets/QPD knowledge bank.xlsx")
```


## Coverage

This guidance applies to everyone working in the production of statistics or other numerical analysis, whether for internal or external use.

## Summary of recommendations

1. Quality assurance should be considered at every step of analysis by everyone involved.
2. Quality assurance should ideally be planned in advance of statistical analysis, with roles, responsibilities, and the extent of assurance activities understood fully by the entire team. 
3. Quality analysis should be appropriate to the scope, risks, methodology, and data source of a piece of analysis. 
4. Analytical and quality assurance processes should be logged in detail as they are carried out. A designated assurer should confirm that a sufficient degree and standard of assurance has been conducted.
5. The quality assurance process and any outstanding quality concerns should be communicated alongside the final results of analysis in order to quantify confidence in the results.

## Introduction

### Defining quality

At the most basic level, the quality of a statistical output may be thought of as its "fitness for purpose" `r addRef(1,44,37,34)`. The ONS Code of Practice uses the five Dimensions of Quality of the European Statistical System (ESS) Code of Practice as criteria for assessing fitness for purpose of statistical outputs. These five dimensions are:

1. Relevance: statistics meet the needs of users
2. Accuracy and Reliability: statistics accurately and reliably portray reality
3. Timeliness and Punctuality: statistics are released in a timely and punctual manner
4. Comparability and Coherence: statistics are consistent internally, over time and 
comparable between regions and countries; it is possible to combine 
and make joint use of related data from different data sources
5. Accessibility and Clarity: statistics are presented in a clear and understandable 
form, released in a suitable and convenient manner, available and 
accessible on an impartial basis with supporting metadata and 
guidance

Quality assurance (QA) of a statistical output is the process of ensuring that these criteria have been met during its production and demonstrating this fact to users.

### Why we need quality assurance

The ONS Code of Practice includes quality as one of the three core pillars that support public confidence in statistics `r addRef(1)`. Under Q3 of the Quality Pillar, the Code of Practice requires all producers of statistics and other analytical outputs to explain how they have assured that their work is accurate, reliable, coherent and timely `r addRef(1)`. Similarly, a key goal of the Government Statistical Service (GSS) Quality Strategy is to ensure our outputs are of sufficient quality and communicate the quality implications to users `r addRef(84)`. 

Thus, we see that there is a requirement not only to guarantee quality but to demonstrate it to users, allowing them to use statistical publications with complete confidence in their validity `r addRef(84,85)`. However, ensuring high quality is also key to building trust among those who are involved in policy and decision making `r addRef(44,37)`. Outputs that attain high levels of fitness-for-purpose allow better decisions to be made with greater efficiency, supporting early trend identification and risk mitigation in the public health sector`r addRef(37, 84,32)`. The Goldacre Review explains the material benefits of high-quality analysis, noting that “these kinds of analyses deliver direct improvements in patient care by identifying problems early, and improving the efficiency of services for all.” `r addRef(84)` The risks posed by poor quality analysis are just as immediate and can include financial and legal damage, as well as, in extreme cases, risks to health and livelihood `r addRef(34)`. It is therefore crucial that internal and external outputs are subject to rigorous quality assurance measures. 

## Roles and responsibilities

Goal 1 of the GSS Quality Strategy sets out the need for everyone involved in statistical production to understand the nature and importance of their role in assuring quality `r addRef(84)`. Team members should understand the exact nature and extent of QA that is planned for a specific project as well as their expected contributions `r addRef(85)`. 

The Aqua Book defines three key roles for QA of statistical analysis: the commissioner, the analyst, and the assurer `r addRef(34, 32)`. While in practice, the exact nature of roles required may differ based on project scope and needs, these provide a useful framework for considering the different ways QA should be incorporated into the life cycle of a project. 
 
The roles can be summarised as follows:

* **The person commissioning analysis** (“the commissioner”) is responsible for developing the question of interest and communicating this to the analyst and assurer so that they are able to identify the most appropriate methods for analysis and assurance. They should clearly express the needs of the project and risks that are entailed so that proportionate levels of QA can be decided upon by the analyst. People of all levels of seniority commission analysis. The commissioner may be acting on behalf of a government decision-maker or other customer, or they may be a policy lead in the area where work is being commissioned. 
* **The person responsible for analysis** (“the analyst”)  must work with the commissioner to help develop the question of interest in a manner that allows it to be answered appropriately as meets the needs of the commissioner. They are responsible for planning and conducting analysis in a methodologically sound way and planning how they will demonstrate assured quality to the commissioner, assurer, and ultimately the end users of the analytical output. As needed, the analyst may bring in third party analysts to provide specialised advice and  quality assurance. Final results and records of all activities undertaken will be provided by the analyst, who must communicate to the commissioner the implications of their results as impacted by its strengths, limitations, uncertainty, and context. In practice, there may often be more than one analyst involved in a project: the use of the term “the analyst” throughout this document is used for brevity’s sake rather than to exclude this possibility.
* **The person responsible for analytical assurance** (“the assurer”) must ensure throughout that appropriate quality assurance is taking place. This person is not necessarily directly involved in conducting QA and does not need to be an analyst themselves, although QA may benefit from an assurer who understands the analytical complexities of the project in order to identify issues with the output. However, the assurer should not be one of the team members involved in conducting the actual analysis. As the assurer must sign off on the QA activities, they should be of sufficient seniority to take responsibility for the output and advise the commissioner on whether quality concerns have been sufficiently addressed and the implications of any remaining risks: typically, they might be a senior analyst or analytical project manager.

More information about what each of these roles entails at each step of the analytical  process can be found in the next section. However, it is important to emphasise that QA does not begin and end with designated roles and project components. Quality can be best guaranteed by a culture of transparency and accountability that promotes continual critical thinking and open communication by all members of a team. This includes encouraging everyone on the team to be open about their mistakes and concerns without fear of repercussions or dismissive responses from senior staff. 

## How is Quality Assurance Conducted?

This section contains examples of questions that can guide QA throughout a project and suggested items of documentation that can be produced. However, the exact scale and scope of these QA activities should be considered on a case-by-case basis, ensuring that they are appropriate and proportionate to the needs of analysis `r addRef(34)`. More rigorous QA will demand more time and resources, and so the extent of QA should be justified by the level of risk present `r addRef(34,85)`. 

### Quality assurance responsibility throughout analysis

The responsibilities described below are examples of how leadership on tasks can be delegated between commissioner, analyst, and assurer. No single member of a team should be responsible for a task in its entirety, without any input from colleagues `r addRef(34)`. Though it may be one person’s job to lead and shape outputs for a specific aspect of analysis, all team members should have a thorough understanding of every stage that allows them to contribute their skills and knowledge toward the final product. 

### Measuring and proving quality: advice for QA log books

At each stage of analysis, documentation should be produced detailing QA measures that have been undertaken. This helps guarantee that analysis and QA are transparent and reproducible, in line with ONS Code of Practice Q3.3 `r addRef(1)`, thereby helping to create high-quality statistics that retain value over time. 

Providing evidence of quality in statistics should be structured around the ESS quality dimensions outlined earlier in this document. One of the most common formats for a QA log is a checklist in the form of an Excel workbook. This is a useful format because it allows QA to be broken down into different stages and quality dimensions by creating different sheets within the workbook. The QA log can then be shared with analysts, commissioners, and assurers to keep all parties updated about the current state of QA activities and allow for assurer sign-off as needed. Such workbooks can also be reused and adapted for different projects, allowing a for consistent QA approach to be applied with greater efficiency. [There is an example spreadsheet available on our GitHub](...) containing examples of checklist elements that may be useful to include in a QA log. While it does not form a complete or comprehensive list of QA concerns, the template is intended to provide a starting point for thinking about the assurance process. Please refer to the guidance within the template for more advice on how to use it. 

### Ensuring data quality

Data may come from any of a large number of sources and may even be gathered by the analysts themselves. The complexities involved in gathering, storing, managing, and accessing data introduce many potential sources of error for a piece of analysis - before analysis even commences! 

Ensuring high quality as the point of data collection is an extremely involved undertaking that depends on a huge number of situational factors and is therefore beyond the scope of this guidance. However, the validation of subsequent stages of the "data lifecycle" bears discussing here as it is a key aspect of ensuring high quality statistical outputs. Under Q3 of the Quality Pillar, the ONS Code of Practice explains that "Statistics should be based on the most appropriate data to meet intended uses. The impact of any data limitations for use should be assessed, minimised and explained." `r addRef(1)` 

When obtaining data from a database or other storage platform, it is most preferable for the analysts themselves to access the data themselves rather than request it from a provider.  However, this may not be possible in some circumstances due to restrictions on data access permissions, and data may have to be requested from the manager of a database. In this case, the data providers should keep detailed records of the queries used to obtain the requested data. Our guidance on reproducible analytical pipelines (RAP) notes that software such as SQL can be used to query databases using code, thus providing a record of how data was obtained. A data provider should ideally also supply information about the format and details of each variable as well as the source and methodology of collection.`r addRef(86,1)` 

In line with [our RAP guidance](...), before data cleaning begins, a copy of the original data should be saved by the analyst. This allows for the data cleaning process to be documented from beginning to end. A degree of manual checking is generally necessary in order for analysts to assess the presence of any unreasonable values or distributions `r addRef(86)`, but automated checks can be built into the data cleaning pipeline as well. Tools such as RMarkdown notebooks can be used to generate detailed summaries of data and flag any potential issues such as outliers or missing values. Any potential bias, uncertainty, or missing values in the data should be documented alongside the implications these have for the final outputs. `r addRef(34)`

### 1. Commissioner engagement

This is usually the most preliminary stage of analysis and focuses on identifying the question that the analysis should address, as well as establishing key context for the analyst’s work. 

#### Suggested documentation:
* Specification or scoping document explaining the intended outcomes of the analysis, including risks and user needs, which may be edited in subsequent stages as details of the requested work change `r addRef(34)`. This can be used at the next stage to help create QA plans regarding relevance (ESS Quality Dimension 1) and user needs. 

#### Responsibilities:
* The **Commissioner** ensures that the intentions and complexities of the problem at hand are clearly communicated and that sufficient resources are secured for the analysis, including for appropriate quality assurance. 
* The	**Analyst** identifies the levels of quality, certainty, and precision that are required for the analysis and communicates with stakeholders to ensure that expectations are aligned with what is possible to deliver
*	The **Assurer** validates the proposed levels of quality and precision and signs off on the scoping document 

#### Guiding questions:
* Have user needs been adequately assessed? `r addRef(34)`.
* Does the planned analysis align with user needs and project priorities? `r addRef(34)`
* Will the proposed time frames allow for adequate quality assurance? `r addRef(34)`
* Have areas of highest risk been identified and addressed? `r addRef(46)`
*	What is our data source? Is data quality-assured and appropriate for our purposes? `r addRef(32)`

### 2. Planning analysis

This stage requires a higher degree of technical input as the commission details are converted into an analysis plan. While a greater degree of responsibility may therefore fall upon the analyst here, it is important for the commissioner to continually confirm that their specified needs will be met by the proposed methodology. 

#### Suggested documentation:
* QA plan that specifies steps that will be taken at each step of the analysis to assure quality.`r addRef(34,46)`. This could include using our [QA log template](...) to create a blank QA log book with a row for each planned check. It may be useful to fill out the project timeline section of the template at this stage, too, to ensure that there is agreement and awareness across the entire team on plans for QA and analysis. This helps promote timeliness and punctuality (ESS Quality Dimension 3).

#### Responsibilities:
* The **Commissioner** maintains contact with the analyst and assurer to continually confirm that time frames will be sufficient for proposed levels of quality assurance
*	The **Analyst** must consider how they will ensure that their work will be robust, accurate, and adequate to address the research question, including considering the limits and uncertainty that these methods will entail and how these will be communicated in the final product. They must also draw up plans for QA of their work, communicating with the assurer to confirm the necessary methods and extent of assurance. How all aspects of the quality dimensions will be met should be carefully planned at this stage in order to ensure that analysis flows smoothly and meets the project needs. 
* The	**Assurer** checks that the proposed level of QA for the analysis will be sufficient for the needs of the project

#### Guiding questions:
*	Is the planned analytical pipeline sufficiently automated, so as to reduce the risk of human error? `r addRef(46,35)`
*	Where automation is not possible, are risks of manual steps sufficiently mitigated?  `r addRef(46)`
*	Is the planned process transparent and reproducible? `r addRef(32)`
*	Are the methods we are using best suited for the project? `r addRef(85)`
*	Have any potential quality issues in the data been sufficiently considered and addressed?  `r addRef(85)`

### 3. Analysis

It is important that analysis and QA of analysis follow written plans exactly, and that any deviation from these plans is thoroughly documented and communicated to the assurer and commissioner. A complete audit trail will allow for the sources of any issues that are identified during QA to be found more quickly. Ensuring a reproducible process is also a key part of aiding in peer reviews and audits after analysis has been completed.

It may aid efficiency to run QA activities parallel to analysis, passing outputs to assurers individually as they are produced. 

#### Suggested documentation:
*	QA log detailing automated and manual validation measures conducted during analysis to ensure results are accurate and reliable (ESS Quality Dimension 2) and coherent when compared to results from other time periods and regions (ESS Quality Dimension 4) `r addRef(34)`. This could involve using a QA log created from [our template](...) to fill out the section on verification and validation. 
*	Technical documentation of methods used `r addRef(34)`
    *	Includes documentation and commenting of code `r addRef(28)`
    *	Records of changes made, ideally managed via version control software such as Git `r addRef(28)`
*	Documentation and justification of assumptions `r addRef(34)`

#### Responsibilities:
* The **Commissioner** ensures that sufficient quality checking of analysis is being conducted for the needs of the project
* The	**Analyst** extracts and manages data, ensuring that data formats, units, and context are understood. They should record details, issues, and assumptions regarding the data and ensure that any instances of missing data are appropriately addressed and the consequences of missing data are recorded. As they follow their analytical plan, they should make note of any changes that they make to the plan as well as all QA measures that have been implemented. Ideally, they should call upon other analysts who are not involved in the project to conduct quality assurance. Issues that these assurers encounter should be flagged immediately and logged alongside measures taken to solve them. Where necessary, the analyst may also draw upon the skill of experts who can provide more specialised technical advice
*	The **Assurer** continually confirms that quality standards are being met and that the level of QA that has been carried out remains sufficient for the decision being supported

#### Guiding questions:
*	Are there any anomalies or unexpected trends in the data? Have they been sufficiently investigated? `r addRef(34,85)`
*	When changes have been made to analysis and QA methodologies, are they justified, well-documented, and clearly communicated? `r addRef(28)`
*	What assumptions does our analysis rely upon? Are these justified? `r addRef(86)`
*	Have the established best practice standards for code been followed? `r addRef(86,28)`

### 4. Delivery of analysis

At this stage, it should be confirmed that the results of analysis are presented in a straightforward and transparent manner with all necessary context. The analysis may be approved in stages and may be sent back and forth between the commissioner, analyst, and assurer several times before it can be finalised. 

#### Suggested documentation:
* QA log of checks conducted on documentation, accessibility, clarity, and other aspects of the analytical publication (ESS Quality Dimension 5). This could involve using a QA log created from [our template](...) to fill out the section on documentation and reproducibility as well as the dection on accessibility and dissemination.
*	QA sign-off by assurer verifying that quality has been assured to the required standard `r addRef(86)`
*	Clarification of data and analysis quality, and the implications on results `r addRef(37)`
*	Quality and methods section of publication `r addRef(47)`

#### Responsibilities:
* The **Commissioner** passes results on to decision-makers and stakeholders, or uploads publication to the relevant platform. Where the analysis has been commissioned specifically for policymaking, the commissioner should ensure that the details of results as well as limitations and outstanding risks are clearly communicated so that the analysis can be used appropriately
* The	**Analyst** ensures that results, risks, and limitations are clearly communicated to the commissioner and well-recorded in the final publication. They should also ensure that any published materials have been quality-assured for accessibility and transparency. They are responsible for ensuring that the QA log has been completed and for obtaining a final sign-off from the assurer verifying this fact. Looking back at the QA process and outcomes, they should reflect on the strong and weak aspects of the analytical process and any errors that were made, considering how they might apply what they have learned to future analysis
*	The **Assurer** confirms that suitable QA has taken place and that an audit trail is in place that clarifies the extent of validation activities. If so, the assurer signs off on the finished product. Otherwise, they should discuss concerns with the analyst and commissioner and ensure these are addressed before authorising delivery

#### Guiding questions:
* Without any input from analytical team, could a third party reproduce our results? `r addRef(86)`
*	If we repeat our processes with different software or methods, will we get the same results? `r addRef(85)`
*	Have strengths and limitations been communicated clearly and effectively to users, stakeholders, and team members? `r addRef(1,35)`
*	Are data visualisations accessible and easy to understand? `r addRef(47)`
* Are sources cited and correctly linked? `r addRef(85,32)`
*	Have technical terms been defined in simple English, if necessary? `r addRef(47)`
*	Is the output accurate and error-free? `r addRef(46)`
*	What lessons have been learned from any errors that were made? `r addRef(46)`
*	If any analyst involved were to leave the organisation or be unavailable, could the analytical process still be repeated? `r addRef(86)`

## References

`r AddReferenceList()`
